{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O14bXTMvnPMt"
      },
      "source": [
        "### Model 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "luonPypvnPMv"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import make_grid\n",
        "from sklearn import metrics\n",
        "import os \n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "def accuracy(target, pred):\n",
        "    return metrics.accuracy_score(target.detach().cpu().numpy(), pred.detach().cpu().numpy())\n",
        "\n",
        "def compute_confusion_matrix(target, pred, normalize=None):\n",
        "    return metrics.confusion_matrix(\n",
        "        target.detach().cpu().numpy(), \n",
        "        pred.detach().cpu().numpy(),\n",
        "        normalize=normalize\n",
        "    )\n",
        "\n",
        "def show_image(img):\n",
        "    img = img.detach().cpu()\n",
        "    img = img / 2 + 0.5   # unnormalize\n",
        "    with sns.axes_style(\"white\"):\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(img.permute((1, 2, 0)).numpy())\n",
        "        plt.axis('off')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "97cf869b5c40442f86047f288f80baa7",
            "30173bdf3a23430da5d1fdd7b3fef390",
            "7093c0b9e2ce4e72ad88d676b9f90709",
            "9ee049a2ad6845c1a2d522a7ffd25950",
            "9480e9ad3da44599b821ca5b2a545486",
            "45067dafb0f943d1bad05f0590abfb96",
            "8811c02a1f214b95b6452a6e35c0963d",
            "f7c397cc4a814ade8b2399d255a2dc8e",
            "91a7be5d62d540b1ad5d598616d541f4",
            "985ba92c89984ccfbcbf7023a9f20158",
            "a161124f1f1245aa8cc5fe4fa0c3bcec"
          ]
        },
        "id": "dONqabKnnPMw",
        "outputId": "acaf0e76-e6ef-40f2-dee4-1bc24fd0c224"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97cf869b5c40442f86047f288f80baa7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# The output of torchvision datasets are PIL images in the range [0, 1]. \n",
        "# We transform them to PyTorch tensors and rescale them to be in the range [-1, 1].\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),  # subtract 0.5 and divide by 0.5\n",
        "    ]\n",
        ")\n",
        "\n",
        "batch_size = 64  # both for training and testing\n",
        "\n",
        "# Load datasets\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, drop_last=False)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, drop_last=True)\n",
        "\n",
        "# Map from class index to class name.\n",
        "classes = {index: name for name, index in train_set.class_to_idx.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxO3EsPTnPMx",
        "outputId": "3e1c563e-ed7d-4df1-977f-3058803c8e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data\n",
            "Number of points: 50000\n",
            "Batch dimension (B x C x H x W): torch.Size([64, 3, 32, 32])\n",
            "Number of distinct labels: 10 (unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n",
            "\n",
            "Test data\n",
            "Number of points: 10000\n",
            "Batch dimension (B x C x H x W): torch.Size([64, 3, 32, 32])\n",
            "Number of distinct labels: 10 (unique labels: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9})\n"
          ]
        }
      ],
      "source": [
        "print(\"Training data\")\n",
        "print(\"Number of points:\", len(train_set))\n",
        "x, y = next(iter(train_loader))\n",
        "print(\"Batch dimension (B x C x H x W):\", x.shape)\n",
        "print(f\"Number of distinct labels: {len(set(train_set.targets))} (unique labels: {set(train_set.targets)})\")\n",
        "\n",
        "print(\"\\nTest data\")\n",
        "print(\"Number of points:\", len(test_set))\n",
        "x, y = next(iter(test_loader))\n",
        "print(\"Batch dimension (B x C x H x W):\", x.shape)\n",
        "print(f\"Number of distinct labels: {len(set(test_set.targets))} (unique labels: {set(test_set.targets)})\")\n",
        "\n",
        "n_classes = len(set(test_set.targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bSes4uaznPMy"
      },
      "outputs": [],
      "source": [
        "# Original Image \n",
        "image_dim = 32\n",
        "chanels_in = 3\n",
        "\n",
        "# Kernel 1\n",
        "chanels_out1 = 32\n",
        "kernel1 = 3\n",
        "padd1 = 1\n",
        "image_dim1 = image_dim - kernel1 + 1 + 2*padd1\n",
        "\n",
        "# Kernel 2\n",
        "chanels_out2 = 64\n",
        "kernel2 = 3\n",
        "padd2 = 1\n",
        "image_dim2 = image_dim1 - kernel2 + 1 + 2*padd2\n",
        "\n",
        "# Max pool: 1st\n",
        "max_pool1 = 2\n",
        "image_dim2_p = image_dim2//max_pool1\n",
        "\n",
        "# Kernel 3\n",
        "chanels_out3 = 128\n",
        "kernel3 = 3\n",
        "padd3 = 1\n",
        "image_dim3 = image_dim2_p - kernel3 + 1 + 2*padd3\n",
        "\n",
        "# kernel 4\n",
        "chanels_out4 = 128\n",
        "kernel4 = 3 \n",
        "padd4 = 1\n",
        "image_dim4 = image_dim3 - kernel4 + 1 + 2*padd4 \n",
        "\n",
        "# Max pool: 2st\n",
        "max_pool2 = 2\n",
        "image_dim4_p = image_dim4//max_pool2\n",
        "\n",
        "# kernel 5\n",
        "chanels_out5 = 256\n",
        "kernel5 = 3 \n",
        "padd5 = 1\n",
        "image_dim5 = image_dim4_p - kernel5 + 1 + 2*padd5 \n",
        "\n",
        "# kernel 6\n",
        "chanels_out6 = 256\n",
        "kernel6 = 3 \n",
        "padd6 = 1\n",
        "image_dim6 = image_dim5 - kernel6 + 1 + 2*padd6\n",
        "\n",
        "# Max pool: 3nd\n",
        "max_pool3 = 2\n",
        "image_dim6p =  image_dim6//max_pool3\n",
        "\n",
        "\n",
        "# Calculate the number of neurons \n",
        "# n_features = chanels_out4*(image_dim5_p)**2  # n_features it's the input in for the neral network\n",
        "n_features = 4096\n",
        "# Hidden Layers \n",
        "hidden_units = [1024, 512, 256]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qYdg3QinPMy"
      },
      "source": [
        "Which type of Kernel is it, Gaussian? Can we change the type?\n",
        "What are exactly the output chanels, Why are they different if we use the same kernel? \n",
        "Can we use different kernels to filter the image and then combine the result in a flatten?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sd_IFZhYnPMy",
        "outputId": "51f9796b-f3a6-4823-d12a-22acf1c5a1e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model2(\n",
            "  (conv_layer): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): ReLU()\n",
            "    (5): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU()\n",
            "    (9): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Dropout2d(p=0.05, inplace=False)\n",
            "    (13): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (14): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): ReLU()\n",
            "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (17): ReLU()\n",
            "    (18): MaxPool2d(kernel_size=(2, 2), stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (19): Flatten(start_dim=1, end_dim=-1)\n",
            "  )\n",
            "  (dense_layer): Sequential(\n",
            "    (0): Dropout(p=0.1, inplace=False)\n",
            "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "    (4): ReLU()\n",
            "    (5): Dropout(p=0.1, inplace=False)\n",
            "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Dropout(p=0.1, inplace=False)\n",
            "    (9): Linear(in_features=256, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class PrintSize(nn.Module):\n",
        "    \"\"\"Utility module to print current shape of a Tensor in Sequential, only at the first pass.\"\"\"\n",
        "    \n",
        "    first = True\n",
        "    \n",
        "    def forward(self, x):\n",
        "        if self.first:\n",
        "            print(f\"Size: {x.size()}\")\n",
        "            self.first = False\n",
        "        return x\n",
        "\n",
        "class Model2(nn.Module):\n",
        "\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.num_classes = n_classes\n",
        "        activation_relu = nn.ReLU\n",
        "        activation_elu = nn.ELU\n",
        "        activation_sig = nn.Sigmoid\n",
        "        activation_sof = nn.Softmax\n",
        "\n",
        "        self.conv_layer = nn.Sequential(\n",
        "\n",
        "            # CONVOLUTION PART\n",
        "            \n",
        "            # Conv 1st Kernel + Batch norm + ReLU \n",
        "            nn.Conv2d(chanels_in, chanels_out1, (kernel1, kernel1), padding=padd1),  # (num_chanels, out_chanels, kernel_size, stride, padding)\n",
        "            nn.BatchNorm2d(chanels_out1),\n",
        "            activation_relu(),\n",
        "\n",
        "            # Conv 2nd Kernel + ReLU + max pool\n",
        "            nn.Conv2d(chanels_out1, chanels_out2, (kernel2, kernel2), padding=padd2),  # (num_chanels, out_chanels, kernel_size, stride, padding)\n",
        "            activation_relu(),\n",
        "            nn.MaxPool2d((max_pool1,max_pool1), stride=2),\n",
        "\n",
        "            # Conv 3th Kernel + Batch norm + ReLU\n",
        "            nn.Conv2d(chanels_out2, chanels_out3, (kernel3, kernel3), padding=padd3),  # (num_chanels, out_chanels, kernel_size, stride, padding)\n",
        "            nn.BatchNorm2d(chanels_out3),\n",
        "            activation_relu(),\n",
        "\n",
        "            # Conv 4th Kernel + ReLU + Maxpool + dropout\n",
        "            nn.Conv2d(chanels_out3, chanels_out4, (kernel4, kernel4), padding=padd4),  # (num_chanels, out_chanels, kernel_size, stride, padding)\n",
        "            activation_relu(),\n",
        "            nn.MaxPool2d((max_pool2,max_pool2), stride=2),\n",
        "            nn.Dropout2d(p=0.05),\n",
        "\n",
        "            # Conv 5th Kernel + batch norm + ReLU\n",
        "            nn.Conv2d(chanels_out4, chanels_out5, (kernel5, kernel5), padding=padd5),\n",
        "            nn.BatchNorm2d(chanels_out5),\n",
        "            activation_relu(),\n",
        "\n",
        "            # Conv 6th Kernel\n",
        "            nn.Conv2d(chanels_out5, chanels_out6, (kernel6, kernel6), padding=padd6),\n",
        "            activation_relu(),\n",
        "            nn.MaxPool2d((max_pool3,max_pool3), stride=2),\n",
        "\n",
        "            # Flatten \n",
        "            nn.Flatten(),\n",
        "        )\n",
        "\n",
        "        self.dense_layer = nn.Sequential(\n",
        "            \n",
        "            # Input Layer\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(n_features, hidden_units[0]),  # (in_features, out_features)\n",
        "            activation_relu(),\n",
        "\n",
        "            # Hidden layer: 1\n",
        "            nn.Linear(hidden_units[0], hidden_units[1]),\n",
        "            activation_relu(),\n",
        "            nn.Dropout(p=0.1),\n",
        "\n",
        "            # Hidden layer 2:\n",
        "            nn.Linear(hidden_units[1], hidden_units[2]),\n",
        "            activation_relu(),\n",
        "            nn.Dropout(p=0.1),\n",
        "\n",
        "            # Output Layer\n",
        "            nn.Linear(hidden_units[2], self.num_classes),\n",
        "                # activation_sof(dim=1)   # Why we don't have to put the softmax? it's already defined ? \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply convolution step \n",
        "        x = self.conv_layer(x)\n",
        "\n",
        "        # Apply dense NN\n",
        "        x = self.dense_layer(x)\n",
        "\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "model2 = Model2(n_classes)\n",
        "device = torch.device('cuda')  # use cuda or cpu\n",
        "model2.to(device)\n",
        "print(model2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Eo8ocluInPMz"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model2.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L979UKi6nPMz",
        "outputId": "5ebc206c-0ad2-4675-e8f4-7de55e31a429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([2, 10])\n",
            "Output logits:\n",
            "[[-0.01234096  0.02201333 -0.00179604  0.02955786 -0.00875029 -0.04393495\n",
            "  -0.00055776 -0.07772359  0.06876911 -0.0855868 ]\n",
            " [ 0.00725805  0.02275951  0.04069508  0.03896881 -0.01002445 -0.0467821\n",
            "   0.00708807 -0.07434189  0.06938757 -0.06958433]]\n",
            "Output probabilities:\n",
            "[[0.0997679  0.10325492 0.10082552 0.10403688 0.10012679 0.09666512\n",
            "  0.10095045 0.0934535  0.10819732 0.09272154]\n",
            " [0.10076876 0.10234299 0.10419513 0.10401542 0.09904218 0.09546772\n",
            "  0.10075162 0.09287257 0.10722805 0.09331548]]\n"
          ]
        }
      ],
      "source": [
        "# Test the forward pass with dummy data\n",
        "out = model2(torch.randn(2, 3, 32, 32, device=device))\n",
        "print(\"Output shape:\", out.size())\n",
        "print(f\"Output logits:\\n{out.detach().cpu().numpy()}\")\n",
        "print(f\"Output probabilities:\\n{out.softmax(1).detach().cpu().numpy()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YN0_FuwdnPM0",
        "outputId": "eb4f44a5-c79c-41d6-94b2-b19a128f6d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 500     training accuracy: 0.10546875\n",
            "             test accuracy: 0.1064\n",
            "Step 1000    training accuracy: 0.12793864678899083\n",
            "             test accuracy: 0.1475\n",
            "Step 1500    training accuracy: 0.1451875\n",
            "             test accuracy: 0.1761\n",
            "Step 2000    training accuracy: 0.17140911697247707\n",
            "             test accuracy: 0.2119\n",
            "Step 2500    training accuracy: 0.2234172077922078\n",
            "             test accuracy: 0.2601\n",
            "Step 3000    training accuracy: 0.23690625\n",
            "             test accuracy: 0.2675\n",
            "Step 3500    training accuracy: 0.2599546370967742\n",
            "             test accuracy: 0.2988\n",
            "Step 4000    training accuracy: 0.2857638888888889\n",
            "             test accuracy: 0.2822\n",
            "Step 4500    training accuracy: 0.29003125\n",
            "             test accuracy: 0.3109\n",
            "Step 5000    training accuracy: 0.3176237824675325\n",
            "             test accuracy: 0.3443\n",
            "Step 5500    training accuracy: 0.35877403846153844\n",
            "             test accuracy: 0.3697\n",
            "Step 6000    training accuracy: 0.3493125\n",
            "             test accuracy: 0.3908\n",
            "Step 6500    training accuracy: 0.37762551229508196\n",
            "             test accuracy: 0.3995\n",
            "Step 7000    training accuracy: 0.391\n",
            "             test accuracy: 0.4116\n",
            "Step 7500    training accuracy: 0.408008658008658\n",
            "             test accuracy: 0.4387\n",
            "Step 8000    training accuracy: 0.42769097222222224\n",
            "             test accuracy: 0.4516\n",
            "Step 8500    training accuracy: 0.43578125\n",
            "             test accuracy: 0.4623\n",
            "Step 9000    training accuracy: 0.451554648241206\n",
            "             test accuracy: 0.4547\n",
            "Step 9500    training accuracy: 0.4703663793103448\n",
            "             test accuracy: 0.484\n",
            "Step 10000   training accuracy: 0.4838125\n",
            "             test accuracy: 0.503\n",
            "Step 10500   training accuracy: 0.4963978293413174\n",
            "             test accuracy: 0.4926\n",
            "Step 11000   training accuracy: 0.5198317307692307\n",
            "             test accuracy: 0.5163\n",
            "Step 11500   training accuracy: 0.5209375\n",
            "             test accuracy: 0.5323\n",
            "Step 12000   training accuracy: 0.5449652777777778\n",
            "             test accuracy: 0.5464\n",
            "Step 12500   training accuracy: 0.54571875\n",
            "             test accuracy: 0.5596\n",
            "Step 13000   training accuracy: 0.5590420081967213\n",
            "             test accuracy: 0.5745\n",
            "Step 13500   training accuracy: 0.5732706310679612\n",
            "             test accuracy: 0.5849\n",
            "Step 14000   training accuracy: 0.5811875\n",
            "             test accuracy: 0.5801\n",
            "Step 14500   training accuracy: 0.5931235259433962\n",
            "             test accuracy: 0.5972\n",
            "Step 15000   training accuracy: 0.609375\n",
            "             test accuracy: 0.6126\n",
            "Step 15500   training accuracy: 0.6146875\n",
            "             test accuracy: 0.619\n",
            "Step 16000   training accuracy: 0.6289496527777778\n",
            "             test accuracy: 0.6193\n",
            "Step 16500   training accuracy: 0.6454326923076923\n",
            "             test accuracy: 0.631\n",
            "Step 17000   training accuracy: 0.6370625\n",
            "             test accuracy: 0.64\n",
            "Step 17500   training accuracy: 0.6561972128378378\n",
            "             test accuracy: 0.642\n",
            "Step 18000   training accuracy: 0.6662946428571429\n",
            "             test accuracy: 0.6475\n",
            "Step 18500   training accuracy: 0.6641875\n",
            "             test accuracy: 0.661\n",
            "Step 19000   training accuracy: 0.6786772629310345\n",
            "             test accuracy: 0.6609\n",
            "Step 19500   training accuracy: 0.677125\n",
            "             test accuracy: 0.6613\n",
            "Step 20000   training accuracy: 0.6875347222222222\n",
            "             test accuracy: 0.6686\n",
            "Step 20500   training accuracy: 0.6980096726190477\n",
            "             test accuracy: 0.6641\n",
            "Step 21000   training accuracy: 0.69678125\n",
            "             test accuracy: 0.6529\n",
            "Step 21500   training accuracy: 0.7048656088082902\n",
            "             test accuracy: 0.6437\n",
            "Step 22000   training accuracy: 0.7243088942307693\n",
            "             test accuracy: 0.6807\n",
            "Step 22500   training accuracy: 0.71296875\n",
            "             test accuracy: 0.682\n",
            "Step 23000   training accuracy: 0.7231657608695652\n",
            "             test accuracy: 0.6939\n",
            "Finished training.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 60\n",
        "num_epochs = 30\n",
        "validation_every_steps = 500\n",
        "\n",
        "step = 0\n",
        "model2.train()\n",
        "\n",
        "train_accuracies = []\n",
        "valid_accuracies = []\n",
        "        \n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    train_accuracies_batches = []\n",
        "    \n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        \n",
        "        # Forward pass, compute gradients, perform one training step.\n",
        "        \n",
        "        # Forward pass.\n",
        "        output = model2(inputs)\n",
        "        \n",
        "        # Compute loss.\n",
        "        loss = loss_fn(output, targets)\n",
        "        \n",
        "        # Clean up gradients from the model.\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Compute gradients based on the loss from the current batch (backpropagation).\n",
        "        loss.backward()\n",
        "        \n",
        "        # Take one optimizer step using the gradients computed in the previous step.\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Increment step counter\n",
        "        step += 1\n",
        "        \n",
        "        # Compute accuracy.\n",
        "        predictions = output.max(1)[1]\n",
        "        train_accuracies_batches.append(accuracy(targets, predictions))\n",
        "        \n",
        "        if step % validation_every_steps == 0:\n",
        "            \n",
        "            # Append average training accuracy to list.\n",
        "            train_accuracies.append(np.mean(train_accuracies_batches))\n",
        "            \n",
        "            train_accuracies_batches = []\n",
        "        \n",
        "            # Compute accuracies on validation set.\n",
        "            valid_accuracies_batches = []\n",
        "            with torch.no_grad():\n",
        "                model2.eval()\n",
        "                for inputs, targets in test_loader:\n",
        "                    inputs, targets = inputs.to(device), targets.to(device)\n",
        "                    output = model2(inputs)\n",
        "                    loss = loss_fn(output, targets)\n",
        "\n",
        "                    predictions = output.max(1)[1]\n",
        "\n",
        "                    # Multiply by len(x) because the final batch of DataLoader may be smaller (drop_last=False).\n",
        "                    valid_accuracies_batches.append(accuracy(targets, predictions) * len(inputs))\n",
        "\n",
        "                model2.train()\n",
        "                \n",
        "            # Append average validation accuracy to list.\n",
        "            valid_accuracies.append(np.sum(valid_accuracies_batches) / len(test_set))\n",
        "     \n",
        "            print(f\"Step {step:<5}   training accuracy: {train_accuracies[-1]}\")\n",
        "            print(f\"             test accuracy: {valid_accuracies[-1]}\")\n",
        "\n",
        "print(\"Finished training.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Zalh7noUqcll"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SW8nPc9znPM0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b300ecb-06d0-4a71-e2d2-c24e7b2e13c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available CUDA devices: ['Tesla T4']\n"
          ]
        }
      ],
      "source": [
        "# Check if we have GPUs available\n",
        "print(\"Available CUDA devices:\", [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IeLY4MN1hx1M"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e52dddd8ca2ba95afe67578a96296e9b17628fddb050e9ee950fdfaca96878c3"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "97cf869b5c40442f86047f288f80baa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30173bdf3a23430da5d1fdd7b3fef390",
              "IPY_MODEL_7093c0b9e2ce4e72ad88d676b9f90709",
              "IPY_MODEL_9ee049a2ad6845c1a2d522a7ffd25950"
            ],
            "layout": "IPY_MODEL_9480e9ad3da44599b821ca5b2a545486"
          }
        },
        "30173bdf3a23430da5d1fdd7b3fef390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45067dafb0f943d1bad05f0590abfb96",
            "placeholder": "​",
            "style": "IPY_MODEL_8811c02a1f214b95b6452a6e35c0963d",
            "value": "100%"
          }
        },
        "7093c0b9e2ce4e72ad88d676b9f90709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c397cc4a814ade8b2399d255a2dc8e",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91a7be5d62d540b1ad5d598616d541f4",
            "value": 170498071
          }
        },
        "9ee049a2ad6845c1a2d522a7ffd25950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_985ba92c89984ccfbcbf7023a9f20158",
            "placeholder": "​",
            "style": "IPY_MODEL_a161124f1f1245aa8cc5fe4fa0c3bcec",
            "value": " 170498071/170498071 [00:14&lt;00:00, 15075480.21it/s]"
          }
        },
        "9480e9ad3da44599b821ca5b2a545486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45067dafb0f943d1bad05f0590abfb96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8811c02a1f214b95b6452a6e35c0963d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c397cc4a814ade8b2399d255a2dc8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a7be5d62d540b1ad5d598616d541f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "985ba92c89984ccfbcbf7023a9f20158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a161124f1f1245aa8cc5fe4fa0c3bcec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}